This part of the code deals with the fLMSci parallel topic placement approach.

1. Run the topic_rationale_generation.py file first to generate topics and rationales from given titles and abstracts.
Example run:
```bash
python topic_rationale_gen.py \
  --input_folder abstracts \
  --output_folder results/abstracts \
  --prompt_path prompts/topic_gen.txt \
  --output_csv results/topics_rationales.csv
  --model gpt-4
  --topics_txt results/unique_topics.txt
```

2. Now, that we have topics and rationales generated lets place them in parallel (in form of chunks of topics) using Llama 3.3 70B with baseline.py. You can replace the models in the code but the current code works for Llama 3.3 70B. We use a seed taxonomy as a start point for starting the placement of topics.
Example run:
```bash
python fLMSci/par/baseline.py \
    --topics_path /path/to/unique_topics.txt \
    --taxonomy_path /path/to/science_seed.json \
    --output_path /path/to/results/taxonomy_creation_outputs.xlsx \
    --chunk_size 100 \
    --max_iterations 2 \
    --retries 1
```

3. Now, after placing topics in parallel we have to merge the taxonomies to create one unified taxonomy using taxonomy_merge.py. We do this using the excel file we generated by running baseline.py.
Example run:
```bash
python merge_taxonomy_outputs.py \
    --excel_path taxonomy_creation_outputs.xlsx \
    --json_output topics_taxonomy.json
```

4. Now, after we have one final taxonomy of topics, we then map our papers to the topics using an excel file (we generated at the first step by running topic_rationale_generation.py). Run map_papers.py to map papers to topics.

```bash
python map_papers.py \
    --csv_path /path/to/results/topics_rationales.csv \
    --taxonomy_path /path/to/results/topics_taxonomy.json \
    --output_path /path/to/results/topics_taxonomy_papers.json
```



